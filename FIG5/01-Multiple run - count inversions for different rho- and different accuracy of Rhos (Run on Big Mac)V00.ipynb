{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp,wilcoxon\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "address_main = '/Users/vu/surfdrive/PostDoc/VUMC projrct/Related Matterials/Positive and unlabeled dataset/Code/estimated rho/'\n",
    "address_data = address_main + 'iris.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(address_data,header= None)\n",
    "df_data.columns = ['x0','x1','x2','x3','text_label']\n",
    "df_data['real_label']=-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_data.loc[df_data['text_label']=='Iris-setosa','real_label'] = +1      # 1\n",
    "#df_data.loc[df_data['text_label']=='Iris-versicolor','real_label'] = +1  # 2\n",
    "df_data.loc[df_data['text_label']=='Iris-virginica','real_label'] = +1    # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_data = len(df_data)\n",
    "minmax = MinMaxScaler()\n",
    "df_data[['x0','x1','x2','x3']] = minmax.fit_transform(df_data[['x0','x1','x2','x3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Classifiers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_counter_ws = 25\n",
    "max_counter_cs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while counter_ws < max_counter_ws:\n",
    "    w = np.random.rand(1,5) *6-3\n",
    "    df_data['predictione'] = predicted_labels(df_data,w)\n",
    "    if (np.sum(df_data['predictione'] == +1) != 0) & (np.sum(df_data['predictione'] == -1) != 0)  :\n",
    "        counter_ws += 1\n",
    "with open(address_main + 'Ws'+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(df_data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic_inversions_F1_= {}\n",
    "dic_inversions_LL = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_in_roh = [0.50, 0.75, 0.9, 0.95, 1 , 1.05, 1.1, 1.25 , 1.5, 2]\n",
    "len(errors_in_roh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      "2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2 1\n",
      "3 0\n",
      "3 1\n",
      "4 0\n",
      "4 1\n",
      "5 0\n",
      "5 1\n",
      "6 0\n",
      "6 1\n",
      "7 0\n",
      "7 1\n",
      "8 0\n",
      "8 1\n",
      "9 0\n",
      "9 1\n",
      "10 0\n",
      "10 1\n",
      "11 0\n",
      "11 1\n",
      "12 0\n",
      "12 1\n",
      "13 0\n",
      "13 1\n",
      "14 0\n",
      "14 1\n",
      "15 0\n",
      "15 1\n",
      "16 0\n",
      "16 1\n",
      "17 0\n",
      "17 1\n",
      "18 0\n",
      "18 1\n",
      "19 0\n",
      "19 1\n",
      "20 0\n",
      "20 1\n",
      "21 0\n",
      "21 1\n",
      "22 0\n",
      "22 1\n",
      "23 0\n",
      "23 1\n",
      "24 0\n",
      "24 1\n",
      "25 0\n",
      "25 1\n",
      "26 0\n",
      "26 1\n",
      "27 0\n",
      "27 1\n",
      "28 0\n",
      "28 1\n",
      "29 0\n",
      "29 1\n",
      "30 0\n",
      "30 1\n",
      "31 0\n",
      "31 1\n",
      "32 0\n",
      "32 1\n",
      "33 0\n",
      "33 1\n",
      "34 0\n",
      "34 1\n",
      "35 0\n",
      "35 1\n",
      "36 0\n",
      "36 1\n",
      "37 0\n",
      "37 1\n",
      "38 0\n",
      "38 1\n",
      "39 0\n",
      "39 1\n",
      "40 0\n",
      "40 1\n",
      "41 0\n",
      "41 1\n",
      "42 0\n",
      "42 1\n",
      "43 0\n",
      "43 1\n",
      "44 0\n",
      "44 1\n",
      "45 0\n",
      "45 1\n",
      "46 0\n",
      "46 1\n",
      "47 0\n",
      "47 1\n",
      "48 0\n",
      "48 1\n",
      "49 0\n",
      "49 1\n",
      "50 0\n",
      "50 1\n"
     ]
    }
   ],
   "source": [
    "c = errors_in_roh[0]\n",
    "for N_visible in range(1,51):\n",
    "    rho_real = N_visible / np.sum(df_data['real_label'] == +1)\n",
    "    rho_estimated = rho_real * rho_real    \n",
    "    dic_inversions_F1_[rho_real]=[]\n",
    "    dic_inversions_LL[rho_real]=[]\n",
    "\n",
    "    for counter_rho in range(0,max_counter_cs):\n",
    "        print(N_visible,counter_rho )\n",
    "        df_data['visible_label'] = -1\n",
    "        temp_visibles = np.random.choice(np.where(df_data['real_label']==+1)[0], size=N_visible, replace=False)\n",
    "        df_data.loc[temp_visibles,'visible_label'] = +1\n",
    "\n",
    "\n",
    "\n",
    "        counter_ws = 0\n",
    "        df_W = pd.DataFrame(columns=['w0','w1','w2','w3','b','F1','F1_','LL'])\n",
    "        while counter_ws < max_counter_ws:\n",
    "            w = np.random.rand(1,5) *6-3\n",
    "            df_data['predictione'] = predicted_labels(df_data,w)\n",
    "\n",
    "            if (np.sum(df_data['predictione'] == +1) != 0) & (np.sum(df_data['predictione'] == -1) != 0)  :\n",
    "                df_W.loc[counter_ws,['w0','w1','w2','w3','b']] = w\n",
    "                df_W.loc[counter_ws,['F1','F1_','LL']] = scores(df=df_data, rho=rho_estimated,writing=False)\n",
    "                counter_ws += 1\n",
    "\n",
    "        dic_inversions_F1_[rho_real].append(count_inversions(df_W['F1'],df_W['F1_']))\n",
    "        dic_inversions_LL[rho_real].append(count_inversions(df_W['F1'],df_W['LL']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(address_main + 'Iric, c=' + ' ' + str(c)+'.pickle', 'wb') as handle:\n",
    "    pickle.dump([dic_inversions_F1_,dic_inversions_LL], handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear Function\n",
    "\n",
    "def g(W,X):\n",
    "    \n",
    "    return np.dot(X,w[0,0:-1]) + w[0,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predicted_labels (df,W):\n",
    "    N_features = W.shape[1] -1\n",
    "    for i in range (0 , len(df)):\n",
    "        Xi = df.iloc[i,0:N_features]\n",
    "        g_xi = g(W, Xi)\n",
    "        if g_xi > 0 :\n",
    "            df.loc[i,'prediction'] = +1\n",
    "        else:\n",
    "            df.loc[i,'prediction'] = -1\n",
    "    return(df['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate scores \n",
    "def scores(df,rho, writing = False):\n",
    "    TP = np.sum((df['prediction'] == +1) &  (df ['real_label'] == +1))\n",
    "    FP = np.sum((df['prediction'] == +1) &  (df ['real_label'] == -1))\n",
    "    FN = np.sum((df['prediction'] == -1) &  (df ['real_label'] == +1))\n",
    "    if writing :\n",
    "        print( 'TP, FP, FN = ', TP, FP, FN)\n",
    "\n",
    "    pr = TP/(TP+FP)\n",
    "    re = TP/(TP+FN)\n",
    "    F_score = 2*pr*re/(pr+re)\n",
    "\n",
    "    TP_ = np.sum((df['prediction'] == +1) &  (df ['visible_label'] == +1))\n",
    "    FP_ = np.sum((df['prediction'] == +1) &  (df ['visible_label'] == -1))\n",
    "    FN_ = np.sum((df['prediction'] == -1) &  (df ['visible_label'] == +1))\n",
    "    if writing :\n",
    "        print( 'TP_, FP_, FN_ = ', TP_, FP_, FN_)\n",
    "    pr_ = TP_/(TP_ + FP_)\n",
    "    pr_ /= rho\n",
    "    re_ = TP_/(TP_ + FN_)\n",
    "    F_score_ = 2*pr_*re_/(pr_+re_)\n",
    "\n",
    "    L_L_score = re_ **2 / np.sum((df['prediction'] == +1))\n",
    "    if writing:\n",
    "        print('np.sum((df[prediction] == +1)) = ', np.sum((df['prediction'] == +1)))\n",
    "    \n",
    "    if np.isnan(F_score):\n",
    "        F_score=0\n",
    "    if np.isnan(F_score_):\n",
    "        F_score_=0\n",
    "    if np.isnan(L_L_score):\n",
    "        L_L_score=0\n",
    "    return (F_score , F_score_, L_L_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def count_inversions(real_F1s, estimated_scores):\n",
    "    errors_h = 0\n",
    "\n",
    "    for i in range(0,len(real_F1s)):\n",
    "        F1_i = real_F1s[i]\n",
    "        F1_h_i = estimated_scores[i]\n",
    "        for j in range(i+1,len(real_F1s)):\n",
    "            F1_j = real_F1s[j]\n",
    "            F1_h_j = estimated_scores[j]\n",
    "\n",
    "\n",
    "            if F1_i > F1_j :\n",
    "                if F1_h_i < F1_h_j:\n",
    "                    errors_h += 1\n",
    "\n",
    "            elif F1_i < F1_j :\n",
    "                if F1_h_i > F1_h_j:\n",
    "                    errors_h +=1\n",
    "                    \n",
    "    errors_h = errors_h / (len(real_F1s)*(len(real_F1s)-1)/2)\n",
    "\n",
    "    return(errors_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
